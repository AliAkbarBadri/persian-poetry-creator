{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tempo.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aliakbarbadri/persian-poetry-creator/blob/master/char-RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF-7m57sBgdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXgkMK0iMQDL",
        "colab_type": "text"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQpHA606p0Et",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ! wget --no-check-certificate https://github.com/aliakbarbadri/persian-poetry-creator/blob/master/Shahnameh.zip?raw=true -O /tmp/Shahnameh.zip\n",
        "# ! unzip /tmp/Shahnameh.zip "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNXP111ZxMKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import os\n",
        "# corpus_url = \"Shahnameh/shahname\"\n",
        "# corpus = \"\"\n",
        "# for filename in os.listdir(corpus_url):\n",
        "#    with open(os.path.join(corpus_url, filename), 'r') as f:\n",
        "#       text = f.read()\n",
        "#       corpus += text\n",
        "#       corpus += \"\\n\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMMBQm7J0n9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# file_corpus = open(\"shahname.txt\", \"a\")\n",
        "# file_corpus.write(corpus)\n",
        "# file_corpus.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8wd1saxwPtu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/aliakbarbadri/persian-poetry-creator/master/shahname.txt\"\n",
        "filepath = keras.utils.get_file(\"shahname.txt\", url) \n",
        "with open(filepath) as f:\n",
        "  corpus = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HB8thb8k3n7C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d0a8c78-3a65-4ba4-b003-2661b9fcc57e"
      },
      "source": [
        "len(corpus)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2555369"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7siNbif14ZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True) \n",
        "tokenizer.fit_on_texts([corpus])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc6yvB8m2SOo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa7f540e-47d6-4383-bded-5b0ade6ed61a"
      },
      "source": [
        "tokenizer.texts_to_sequences([\"سلام\"])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[14, 25, 2, 10]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91M_KbVg2b0p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3b2170d-62ef-4d0e-b327-4d0694e6fcd6"
      },
      "source": [
        "tokenizer.sequences_to_texts([[14, 25, 2, 10]])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['س ل ا م']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOL6FamJHEmT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cced0bba-2c48-424a-c94a-e935b34961a6"
      },
      "source": [
        "\"\".join(sorted(set(corpus)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\t\\n ()«»،؟ءآأؤئابتثجحخدذرزسشصضطظعغفقلمنهؤپچژکگی\\u200c'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwLhbfzn24ng",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "03ce2a99-eaf6-4834-c638-5c9cc3d75eae"
      },
      "source": [
        "max_id = len(tokenizer.word_index)\n",
        "dataset_size = len(corpus)\n",
        "max_id,dataset_size"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48, 2555369)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRlaPKLg3K72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[encoded] = np.array(tokenizer.texts_to_sequences([corpus])) - 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcBdBlTx7ObM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_size = dataset_size * 90 // 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mdl5R3vMqFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_steps = 100\n",
        "window_length = n_steps + 1 # target = input shifted 1 character ahead \n",
        "batch_size = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yADuVEnNMGn9",
        "colab_type": "text"
      },
      "source": [
        "# Stateless RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcW5gHHQHxR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
        "# dataset = dataset.window(window_length, shift=1, drop_remainder=True)\n",
        "# dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
        "# dataset = dataset.shuffle(10000).batch(batch_size)\n",
        "# dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "# dataset = dataset.map(lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
        "# dataset = dataset.prefetch(1)\n",
        "# for X_batch, Y_batch in dataset.take(1):\n",
        "#     print(X_batch.shape, Y_batch.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l58r5_yUH7an",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = keras.models.Sequential([\n",
        "#     tf.compat.v1.keras.layers.CuDNNGRU(128, return_sequences=True, \n",
        "#                                        input_shape=[None, max_id],\n",
        "#                                        recurrent_regularizer=keras.regularizers.l2(1e-4)),\n",
        "#     tf.compat.v1.keras.layers.CuDNNGRU(128, return_sequences=True,\n",
        "#                                        recurrent_regularizer=keras.regularizers.l2(1e-4)),\n",
        "#     keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
        "#                                                     activation=\"softmax\"))\n",
        "# ])\n",
        "# model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl52USe68SY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# history = model.fit(dataset, steps_per_epoch=train_size // batch_size,epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79DsC3GF_AXJ",
        "colab_type": "text"
      },
      "source": [
        "# Stateful RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDadSOwDNGJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krUiNumtsezJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
        "dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True) \n",
        "dataset = dataset.flat_map(lambda window: window.batch(window_length)) \n",
        "dataset = dataset.batch(1)\n",
        "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:])) \n",
        "dataset = dataset.map(lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch)) \n",
        "dataset = dataset.prefetch(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trfxUh1cNPQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "encoded_parts = np.array_split(encoded[:train_size], batch_size)\n",
        "datasets = []\n",
        "for encoded_part in encoded_parts:\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(encoded_part)\n",
        "    dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
        "    dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
        "    datasets.append(dataset)\n",
        "dataset = tf.data.Dataset.zip(tuple(datasets)).map(lambda *windows: tf.stack(windows))\n",
        "dataset = dataset.repeat().map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "dataset = dataset.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
        "dataset = dataset.prefetch(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exV4TXA1sjmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "  keras.layers.GRU(128, return_sequences=True, stateful=True,recurrent_regularizer=keras.regularizers.l2(1e-2),\n",
        "                    batch_input_shape=[batch_size, None, max_id]), \n",
        "  keras.layers.GRU(128, return_sequences=True, stateful=True,recurrent_regularizer=keras.regularizers.l2(1e-2)),                   \n",
        "  keras.layers.TimeDistributed(keras.layers.Dense(max_id,activation=\"softmax\"))\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lduJTFVBuc6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResetStatesCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs):\n",
        "        self.model.reset_states()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rydTueveJ5Mw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
        "steps_per_epoch = train_size // batch_size // n_steps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emLfOPT7-l5i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a86e9977-31b6-45e7-9219-d915c75bd26d"
      },
      "source": [
        "history = model.fit(dataset, steps_per_epoch=steps_per_epoch, epochs=50, callbacks=[ResetStatesCallback()])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 2.5722\n",
            "Epoch 2/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 2.1264\n",
            "Epoch 3/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.9908\n",
            "Epoch 4/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.9233\n",
            "Epoch 5/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.8767\n",
            "Epoch 6/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.8403\n",
            "Epoch 7/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.8101\n",
            "Epoch 8/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.7858\n",
            "Epoch 9/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.7648\n",
            "Epoch 10/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.7463\n",
            "Epoch 11/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.7299\n",
            "Epoch 12/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.7150\n",
            "Epoch 13/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.6989\n",
            "Epoch 14/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.6767\n",
            "Epoch 15/50\n",
            "718/718 [==============================] - 35s 48ms/step - loss: 1.6625\n",
            "Epoch 16/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.6522\n",
            "Epoch 17/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.6433\n",
            "Epoch 18/50\n",
            "718/718 [==============================] - 35s 48ms/step - loss: 1.6353\n",
            "Epoch 19/50\n",
            "718/718 [==============================] - 35s 48ms/step - loss: 1.6279\n",
            "Epoch 20/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.6211\n",
            "Epoch 21/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.6148\n",
            "Epoch 22/50\n",
            "718/718 [==============================] - 35s 48ms/step - loss: 1.6090\n",
            "Epoch 23/50\n",
            "718/718 [==============================] - 35s 48ms/step - loss: 1.6036\n",
            "Epoch 24/50\n",
            "718/718 [==============================] - 35s 48ms/step - loss: 1.5985\n",
            "Epoch 25/50\n",
            "718/718 [==============================] - 35s 48ms/step - loss: 1.5938\n",
            "Epoch 26/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.5893\n",
            "Epoch 27/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.5851\n",
            "Epoch 28/50\n",
            "718/718 [==============================] - 35s 48ms/step - loss: 1.5811\n",
            "Epoch 29/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.5772\n",
            "Epoch 30/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.5736\n",
            "Epoch 31/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.5701\n",
            "Epoch 32/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.5668\n",
            "Epoch 33/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.5636\n",
            "Epoch 34/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.5605\n",
            "Epoch 35/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.5576\n",
            "Epoch 36/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.5548\n",
            "Epoch 37/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.5520\n",
            "Epoch 38/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.5494\n",
            "Epoch 39/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.5469\n",
            "Epoch 40/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.5444\n",
            "Epoch 41/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.5421\n",
            "Epoch 42/50\n",
            "718/718 [==============================] - 36s 49ms/step - loss: 1.5398\n",
            "Epoch 43/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.5376\n",
            "Epoch 44/50\n",
            "718/718 [==============================] - 36s 50ms/step - loss: 1.5354\n",
            "Epoch 45/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.5333\n",
            "Epoch 46/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.5313\n",
            "Epoch 47/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.5294\n",
            "Epoch 48/50\n",
            "718/718 [==============================] - 36s 49ms/step - loss: 1.5275\n",
            "Epoch 49/50\n",
            "718/718 [==============================] - 36s 49ms/step - loss: 1.5256\n",
            "Epoch 50/50\n",
            "718/718 [==============================] - 35s 49ms/step - loss: 1.5238\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLt_nzjN-mO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stateless_model = keras.models.Sequential([\n",
        "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id]),\n",
        "    keras.layers.GRU(128, return_sequences=True),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,activation=\"softmax\"))\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0ZueaJP-qfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stateless_model.build(tf.TensorShape([None, None, max_id]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je-VPOVq-s9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stateless_model.set_weights(model.get_weights())\n",
        "model = stateless_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0uyqIpTbJ4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"char_rnn_gru.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hwUaRmbMApR",
        "colab_type": "text"
      },
      "source": [
        "# Use model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7gJPrQIWBFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(texts):\n",
        "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
        "    return tf.one_hot(X, max_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mlj1j_XWGpV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "b3fd6bb8-1520-4e21-95ad-453903c01bb2"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "X_new = preprocess([\"که\"])\n",
        "Y_pred = model.predict_classes(X_new)\n",
        "tokenizer.sequences_to_texts(Y_pred + 1)[0][-1] # 1st sentence, last char"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-26-c089b4297ff4>:5: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FK60cXmWI0b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d1f582c3-a270-4715-bdc2-7d1a75c726e3"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "tf.random.categorical([[np.log(0.5), np.log(0.4), np.log(0.1)]], num_samples=40).numpy()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
              "        2, 0, 0, 1, 1, 1, 0, 0, 1, 2, 0, 0, 1, 1, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bWFUO7PWKO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def next_char(text, temperature=1):\n",
        "    X_new = preprocess([text])\n",
        "    y_proba = model.predict(X_new)[0, -1:, :]\n",
        "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
        "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
        "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K0Cwek-WMIs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42a01e68-e9fd-49c8-a627-523efd6acc95"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "next_char(\"که ایران چو با\", temperature=1)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKgcpFTeWPAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def complete_text(text, n_chars=100, temperature=1):\n",
        "    for _ in range(n_chars):\n",
        "        text += next_char(text, temperature)\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5jAKgmNWRSq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "bf5c9480-99e3-45ff-e29d-218a70095b99"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "print(complete_text(\"که ایران چو باغی ست خرم بهار\", temperature=1))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "که ایران چو باغی ست خرم بهار\n",
            "پس از دیدم و گنجی بدیدش‌ه\tهمان غم جلست و بنگره\n",
            "دگرگون چون که دارا گهر جانت\tجهابد رسیدار و زیربفشاند\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}